// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumiverse.Scaleway
{
    /// <summary>
    /// Creates and manages Scaleway Managed Inference deployments.
    /// For more information, see the [API documentation](https://www.scaleway.com/en/developers/api/inference/).
    /// 
    /// ## Example Usage
    /// 
    /// ### Basic
    /// 
    /// ## Import
    /// 
    /// Functions can be imported using, `{region}/{id}`, as shown below:
    /// 
    /// bash
    /// 
    /// ```sh
    /// $ pulumi import scaleway:index/inferenceDeployment:InferenceDeployment deployment fr-par/11111111-1111-1111-1111-111111111111
    /// ```
    /// </summary>
    [Obsolete(@"scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment")]
    [ScalewayResourceType("scaleway:index/inferenceDeployment:InferenceDeployment")]
    public partial class InferenceDeployment : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Some models (e.g Meta Llama) require end-user license agreements. Set `True` to accept.
        /// </summary>
        [Output("acceptEula")]
        public Output<bool?> AcceptEula { get; private set; } = null!;

        /// <summary>
        /// The date and time of the creation of the deployment.
        /// </summary>
        [Output("createdAt")]
        public Output<string> CreatedAt { get; private set; } = null!;

        /// <summary>
        /// The maximum size of the pool.
        /// </summary>
        [Output("maxSize")]
        public Output<int?> MaxSize { get; private set; } = null!;

        /// <summary>
        /// The minimum size of the pool.
        /// </summary>
        [Output("minSize")]
        public Output<int?> MinSize { get; private set; } = null!;

        /// <summary>
        /// The model id used for the deployment.
        /// </summary>
        [Output("modelId")]
        public Output<string> ModelId { get; private set; } = null!;

        /// <summary>
        /// The model name used for the deployment. Model names can be found in Console or using Scaleway's CLI (`scw inference model list`)
        /// </summary>
        [Output("modelName")]
        public Output<string> ModelName { get; private set; } = null!;

        /// <summary>
        /// The deployment name.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
        /// </summary>
        [Output("nodeType")]
        public Output<string> NodeType { get; private set; } = null!;

        /// <summary>
        /// Configuration of the deployment's private endpoint.
        /// </summary>
        [Output("privateEndpoint")]
        public Output<Outputs.InferenceDeploymentPrivateEndpoint?> PrivateEndpoint { get; private set; } = null!;

        /// <summary>
        /// The private IPv4 address associated with the deployment.
        /// </summary>
        [Output("privateIps")]
        public Output<ImmutableArray<Outputs.InferenceDeploymentPrivateIp>> PrivateIps { get; private set; } = null!;

        /// <summary>
        /// `ProjectId`) The ID of the project the deployment is associated with.
        /// </summary>
        [Output("projectId")]
        public Output<string> ProjectId { get; private set; } = null!;

        /// <summary>
        /// Configuration of the deployment's public endpoint.
        /// </summary>
        [Output("publicEndpoint")]
        public Output<Outputs.InferenceDeploymentPublicEndpoint?> PublicEndpoint { get; private set; } = null!;

        /// <summary>
        /// The number of bits each model parameter should be quantized to
        /// </summary>
        [Output("quantization")]
        public Output<int?> Quantization { get; private set; } = null!;

        /// <summary>
        /// `Region`) The region in which the deployment is created.
        /// </summary>
        [Output("region")]
        public Output<string?> Region { get; private set; } = null!;

        /// <summary>
        /// The size of the pool.
        /// </summary>
        [Output("size")]
        public Output<int> Size { get; private set; } = null!;

        /// <summary>
        /// The status of the deployment.
        /// </summary>
        [Output("status")]
        public Output<string> Status { get; private set; } = null!;

        /// <summary>
        /// The tags associated with the deployment.
        /// </summary>
        [Output("tags")]
        public Output<ImmutableArray<string>> Tags { get; private set; } = null!;

        /// <summary>
        /// The date and time of the last update of the deployment.
        /// </summary>
        [Output("updatedAt")]
        public Output<string> UpdatedAt { get; private set; } = null!;


        /// <summary>
        /// Create a InferenceDeployment resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public InferenceDeployment(string name, InferenceDeploymentArgs args, CustomResourceOptions? options = null)
            : base("scaleway:index/inferenceDeployment:InferenceDeployment", name, args ?? new InferenceDeploymentArgs(), MakeResourceOptions(options, ""))
        {
        }

        private InferenceDeployment(string name, Input<string> id, InferenceDeploymentState? state = null, CustomResourceOptions? options = null)
            : base("scaleway:index/inferenceDeployment:InferenceDeployment", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                PluginDownloadURL = "github://api.github.com/pulumiverse",
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing InferenceDeployment resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static InferenceDeployment Get(string name, Input<string> id, InferenceDeploymentState? state = null, CustomResourceOptions? options = null)
        {
            return new InferenceDeployment(name, id, state, options);
        }
    }

    public sealed class InferenceDeploymentArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Some models (e.g Meta Llama) require end-user license agreements. Set `True` to accept.
        /// </summary>
        [Input("acceptEula")]
        public Input<bool>? AcceptEula { get; set; }

        /// <summary>
        /// The maximum size of the pool.
        /// </summary>
        [Input("maxSize")]
        public Input<int>? MaxSize { get; set; }

        /// <summary>
        /// The minimum size of the pool.
        /// </summary>
        [Input("minSize")]
        public Input<int>? MinSize { get; set; }

        /// <summary>
        /// The model id used for the deployment.
        /// </summary>
        [Input("modelId", required: true)]
        public Input<string> ModelId { get; set; } = null!;

        /// <summary>
        /// The deployment name.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
        /// </summary>
        [Input("nodeType", required: true)]
        public Input<string> NodeType { get; set; } = null!;

        /// <summary>
        /// Configuration of the deployment's private endpoint.
        /// </summary>
        [Input("privateEndpoint")]
        public Input<Inputs.InferenceDeploymentPrivateEndpointArgs>? PrivateEndpoint { get; set; }

        [Input("privateIps")]
        private InputList<Inputs.InferenceDeploymentPrivateIpArgs>? _privateIps;

        /// <summary>
        /// The private IPv4 address associated with the deployment.
        /// </summary>
        public InputList<Inputs.InferenceDeploymentPrivateIpArgs> PrivateIps
        {
            get => _privateIps ?? (_privateIps = new InputList<Inputs.InferenceDeploymentPrivateIpArgs>());
            set => _privateIps = value;
        }

        /// <summary>
        /// `ProjectId`) The ID of the project the deployment is associated with.
        /// </summary>
        [Input("projectId")]
        public Input<string>? ProjectId { get; set; }

        /// <summary>
        /// Configuration of the deployment's public endpoint.
        /// </summary>
        [Input("publicEndpoint")]
        public Input<Inputs.InferenceDeploymentPublicEndpointArgs>? PublicEndpoint { get; set; }

        /// <summary>
        /// The number of bits each model parameter should be quantized to
        /// </summary>
        [Input("quantization")]
        public Input<int>? Quantization { get; set; }

        /// <summary>
        /// `Region`) The region in which the deployment is created.
        /// </summary>
        [Input("region")]
        public Input<string>? Region { get; set; }

        [Input("tags")]
        private InputList<string>? _tags;

        /// <summary>
        /// The tags associated with the deployment.
        /// </summary>
        public InputList<string> Tags
        {
            get => _tags ?? (_tags = new InputList<string>());
            set => _tags = value;
        }

        public InferenceDeploymentArgs()
        {
        }
        public static new InferenceDeploymentArgs Empty => new InferenceDeploymentArgs();
    }

    public sealed class InferenceDeploymentState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Some models (e.g Meta Llama) require end-user license agreements. Set `True` to accept.
        /// </summary>
        [Input("acceptEula")]
        public Input<bool>? AcceptEula { get; set; }

        /// <summary>
        /// The date and time of the creation of the deployment.
        /// </summary>
        [Input("createdAt")]
        public Input<string>? CreatedAt { get; set; }

        /// <summary>
        /// The maximum size of the pool.
        /// </summary>
        [Input("maxSize")]
        public Input<int>? MaxSize { get; set; }

        /// <summary>
        /// The minimum size of the pool.
        /// </summary>
        [Input("minSize")]
        public Input<int>? MinSize { get; set; }

        /// <summary>
        /// The model id used for the deployment.
        /// </summary>
        [Input("modelId")]
        public Input<string>? ModelId { get; set; }

        /// <summary>
        /// The model name used for the deployment. Model names can be found in Console or using Scaleway's CLI (`scw inference model list`)
        /// </summary>
        [Input("modelName")]
        public Input<string>? ModelName { get; set; }

        /// <summary>
        /// The deployment name.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
        /// </summary>
        [Input("nodeType")]
        public Input<string>? NodeType { get; set; }

        /// <summary>
        /// Configuration of the deployment's private endpoint.
        /// </summary>
        [Input("privateEndpoint")]
        public Input<Inputs.InferenceDeploymentPrivateEndpointGetArgs>? PrivateEndpoint { get; set; }

        [Input("privateIps")]
        private InputList<Inputs.InferenceDeploymentPrivateIpGetArgs>? _privateIps;

        /// <summary>
        /// The private IPv4 address associated with the deployment.
        /// </summary>
        public InputList<Inputs.InferenceDeploymentPrivateIpGetArgs> PrivateIps
        {
            get => _privateIps ?? (_privateIps = new InputList<Inputs.InferenceDeploymentPrivateIpGetArgs>());
            set => _privateIps = value;
        }

        /// <summary>
        /// `ProjectId`) The ID of the project the deployment is associated with.
        /// </summary>
        [Input("projectId")]
        public Input<string>? ProjectId { get; set; }

        /// <summary>
        /// Configuration of the deployment's public endpoint.
        /// </summary>
        [Input("publicEndpoint")]
        public Input<Inputs.InferenceDeploymentPublicEndpointGetArgs>? PublicEndpoint { get; set; }

        /// <summary>
        /// The number of bits each model parameter should be quantized to
        /// </summary>
        [Input("quantization")]
        public Input<int>? Quantization { get; set; }

        /// <summary>
        /// `Region`) The region in which the deployment is created.
        /// </summary>
        [Input("region")]
        public Input<string>? Region { get; set; }

        /// <summary>
        /// The size of the pool.
        /// </summary>
        [Input("size")]
        public Input<int>? Size { get; set; }

        /// <summary>
        /// The status of the deployment.
        /// </summary>
        [Input("status")]
        public Input<string>? Status { get; set; }

        [Input("tags")]
        private InputList<string>? _tags;

        /// <summary>
        /// The tags associated with the deployment.
        /// </summary>
        public InputList<string> Tags
        {
            get => _tags ?? (_tags = new InputList<string>());
            set => _tags = value;
        }

        /// <summary>
        /// The date and time of the last update of the deployment.
        /// </summary>
        [Input("updatedAt")]
        public Input<string>? UpdatedAt { get; set; }

        public InferenceDeploymentState()
        {
        }
        public static new InferenceDeploymentState Empty => new InferenceDeploymentState();
    }
}
