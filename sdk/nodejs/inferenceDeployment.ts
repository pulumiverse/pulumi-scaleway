// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * Creates and manages Scaleway Managed Inference deployments.
 * For more information, see the [API documentation](https://www.scaleway.com/en/developers/api/inference/).
 *
 * ## Example Usage
 *
 * ### Basic
 *
 * ## Import
 *
 * Functions can be imported using, `{region}/{id}`, as shown below:
 *
 * bash
 *
 * ```sh
 * $ pulumi import scaleway:index/inferenceDeployment:InferenceDeployment deployment fr-par/11111111-1111-1111-1111-111111111111
 * ```
 *
 * @deprecated scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment
 */
export class InferenceDeployment extends pulumi.CustomResource {
    /**
     * Get an existing InferenceDeployment resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: InferenceDeploymentState, opts?: pulumi.CustomResourceOptions): InferenceDeployment {
        pulumi.log.warn("InferenceDeployment is deprecated: scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment")
        return new InferenceDeployment(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'scaleway:index/inferenceDeployment:InferenceDeployment';

    /**
     * Returns true if the given object is an instance of InferenceDeployment.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is InferenceDeployment {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === InferenceDeployment.__pulumiType;
    }

    /**
     * Some models (e.g Meta Llama) require end-user license agreements. Set `true` to accept.
     */
    declare public readonly acceptEula: pulumi.Output<boolean | undefined>;
    /**
     * The date and time of the creation of the deployment.
     */
    declare public /*out*/ readonly createdAt: pulumi.Output<string>;
    /**
     * The maximum size of the pool.
     */
    declare public readonly maxSize: pulumi.Output<number | undefined>;
    /**
     * The minimum size of the pool.
     */
    declare public readonly minSize: pulumi.Output<number | undefined>;
    /**
     * The model id used for the deployment.
     */
    declare public readonly modelId: pulumi.Output<string>;
    /**
     * The model name used for the deployment. Model names can be found in Console or using Scaleway's CLI (`scw inference model list`)
     */
    declare public /*out*/ readonly modelName: pulumi.Output<string>;
    /**
     * The deployment name.
     */
    declare public readonly name: pulumi.Output<string>;
    /**
     * The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
     */
    declare public readonly nodeType: pulumi.Output<string>;
    /**
     * Configuration of the deployment's private endpoint.
     */
    declare public readonly privateEndpoint: pulumi.Output<outputs.InferenceDeploymentPrivateEndpoint | undefined>;
    /**
     * The private IPv4 address associated with the deployment.
     */
    declare public readonly privateIps: pulumi.Output<outputs.InferenceDeploymentPrivateIp[]>;
    /**
     * `projectId`) The ID of the project the deployment is associated with.
     */
    declare public readonly projectId: pulumi.Output<string>;
    /**
     * Configuration of the deployment's public endpoint.
     */
    declare public readonly publicEndpoint: pulumi.Output<outputs.InferenceDeploymentPublicEndpoint | undefined>;
    /**
     * The number of bits each model parameter should be quantized to
     */
    declare public readonly quantization: pulumi.Output<number | undefined>;
    /**
     * `region`) The region in which the deployment is created.
     */
    declare public readonly region: pulumi.Output<string | undefined>;
    /**
     * The size of the pool.
     */
    declare public /*out*/ readonly size: pulumi.Output<number>;
    /**
     * The status of the deployment.
     */
    declare public /*out*/ readonly status: pulumi.Output<string>;
    /**
     * The tags associated with the deployment.
     */
    declare public readonly tags: pulumi.Output<string[] | undefined>;
    /**
     * The date and time of the last update of the deployment.
     */
    declare public /*out*/ readonly updatedAt: pulumi.Output<string>;

    /**
     * Create a InferenceDeployment resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    /** @deprecated scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment */
    constructor(name: string, args: InferenceDeploymentArgs, opts?: pulumi.CustomResourceOptions)
    /** @deprecated scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment */
    constructor(name: string, argsOrState?: InferenceDeploymentArgs | InferenceDeploymentState, opts?: pulumi.CustomResourceOptions) {
        pulumi.log.warn("InferenceDeployment is deprecated: scaleway.index/inferencedeployment.InferenceDeployment has been deprecated in favor of scaleway.inference/deployment.Deployment")
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as InferenceDeploymentState | undefined;
            resourceInputs["acceptEula"] = state?.acceptEula;
            resourceInputs["createdAt"] = state?.createdAt;
            resourceInputs["maxSize"] = state?.maxSize;
            resourceInputs["minSize"] = state?.minSize;
            resourceInputs["modelId"] = state?.modelId;
            resourceInputs["modelName"] = state?.modelName;
            resourceInputs["name"] = state?.name;
            resourceInputs["nodeType"] = state?.nodeType;
            resourceInputs["privateEndpoint"] = state?.privateEndpoint;
            resourceInputs["privateIps"] = state?.privateIps;
            resourceInputs["projectId"] = state?.projectId;
            resourceInputs["publicEndpoint"] = state?.publicEndpoint;
            resourceInputs["quantization"] = state?.quantization;
            resourceInputs["region"] = state?.region;
            resourceInputs["size"] = state?.size;
            resourceInputs["status"] = state?.status;
            resourceInputs["tags"] = state?.tags;
            resourceInputs["updatedAt"] = state?.updatedAt;
        } else {
            const args = argsOrState as InferenceDeploymentArgs | undefined;
            if (args?.modelId === undefined && !opts.urn) {
                throw new Error("Missing required property 'modelId'");
            }
            if (args?.nodeType === undefined && !opts.urn) {
                throw new Error("Missing required property 'nodeType'");
            }
            resourceInputs["acceptEula"] = args?.acceptEula;
            resourceInputs["maxSize"] = args?.maxSize;
            resourceInputs["minSize"] = args?.minSize;
            resourceInputs["modelId"] = args?.modelId;
            resourceInputs["name"] = args?.name;
            resourceInputs["nodeType"] = args?.nodeType;
            resourceInputs["privateEndpoint"] = args?.privateEndpoint;
            resourceInputs["privateIps"] = args?.privateIps;
            resourceInputs["projectId"] = args?.projectId;
            resourceInputs["publicEndpoint"] = args?.publicEndpoint;
            resourceInputs["quantization"] = args?.quantization;
            resourceInputs["region"] = args?.region;
            resourceInputs["tags"] = args?.tags;
            resourceInputs["createdAt"] = undefined /*out*/;
            resourceInputs["modelName"] = undefined /*out*/;
            resourceInputs["size"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
            resourceInputs["updatedAt"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(InferenceDeployment.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering InferenceDeployment resources.
 */
export interface InferenceDeploymentState {
    /**
     * Some models (e.g Meta Llama) require end-user license agreements. Set `true` to accept.
     */
    acceptEula?: pulumi.Input<boolean>;
    /**
     * The date and time of the creation of the deployment.
     */
    createdAt?: pulumi.Input<string>;
    /**
     * The maximum size of the pool.
     */
    maxSize?: pulumi.Input<number>;
    /**
     * The minimum size of the pool.
     */
    minSize?: pulumi.Input<number>;
    /**
     * The model id used for the deployment.
     */
    modelId?: pulumi.Input<string>;
    /**
     * The model name used for the deployment. Model names can be found in Console or using Scaleway's CLI (`scw inference model list`)
     */
    modelName?: pulumi.Input<string>;
    /**
     * The deployment name.
     */
    name?: pulumi.Input<string>;
    /**
     * The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
     */
    nodeType?: pulumi.Input<string>;
    /**
     * Configuration of the deployment's private endpoint.
     */
    privateEndpoint?: pulumi.Input<inputs.InferenceDeploymentPrivateEndpoint>;
    /**
     * The private IPv4 address associated with the deployment.
     */
    privateIps?: pulumi.Input<pulumi.Input<inputs.InferenceDeploymentPrivateIp>[]>;
    /**
     * `projectId`) The ID of the project the deployment is associated with.
     */
    projectId?: pulumi.Input<string>;
    /**
     * Configuration of the deployment's public endpoint.
     */
    publicEndpoint?: pulumi.Input<inputs.InferenceDeploymentPublicEndpoint>;
    /**
     * The number of bits each model parameter should be quantized to
     */
    quantization?: pulumi.Input<number>;
    /**
     * `region`) The region in which the deployment is created.
     */
    region?: pulumi.Input<string>;
    /**
     * The size of the pool.
     */
    size?: pulumi.Input<number>;
    /**
     * The status of the deployment.
     */
    status?: pulumi.Input<string>;
    /**
     * The tags associated with the deployment.
     */
    tags?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * The date and time of the last update of the deployment.
     */
    updatedAt?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a InferenceDeployment resource.
 */
export interface InferenceDeploymentArgs {
    /**
     * Some models (e.g Meta Llama) require end-user license agreements. Set `true` to accept.
     */
    acceptEula?: pulumi.Input<boolean>;
    /**
     * The maximum size of the pool.
     */
    maxSize?: pulumi.Input<number>;
    /**
     * The minimum size of the pool.
     */
    minSize?: pulumi.Input<number>;
    /**
     * The model id used for the deployment.
     */
    modelId: pulumi.Input<string>;
    /**
     * The deployment name.
     */
    name?: pulumi.Input<string>;
    /**
     * The node type to use for the deployment. Node types can be found using Scaleway's CLI (`scw inference node-type list`)
     */
    nodeType: pulumi.Input<string>;
    /**
     * Configuration of the deployment's private endpoint.
     */
    privateEndpoint?: pulumi.Input<inputs.InferenceDeploymentPrivateEndpoint>;
    /**
     * The private IPv4 address associated with the deployment.
     */
    privateIps?: pulumi.Input<pulumi.Input<inputs.InferenceDeploymentPrivateIp>[]>;
    /**
     * `projectId`) The ID of the project the deployment is associated with.
     */
    projectId?: pulumi.Input<string>;
    /**
     * Configuration of the deployment's public endpoint.
     */
    publicEndpoint?: pulumi.Input<inputs.InferenceDeploymentPublicEndpoint>;
    /**
     * The number of bits each model parameter should be quantized to
     */
    quantization?: pulumi.Input<number>;
    /**
     * `region`) The region in which the deployment is created.
     */
    region?: pulumi.Input<string>;
    /**
     * The tags associated with the deployment.
     */
    tags?: pulumi.Input<pulumi.Input<string>[]>;
}
